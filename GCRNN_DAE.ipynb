{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f659b7-5cbe-40cc-9f92-c0eb4f824392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, LSTM, Dense, TimeDistributed, Conv1D, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e5460c-8d65-4673-9cf9-ff14a07e86e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1342, 128, 128)\n",
      "Test data shape: (336, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "def preprocess_audio(audio_path, target_sr=22050, n_fft=2048, hop_length=512, n_mels=128, fixed_length=128):\n",
    "    \"\"\"\n",
    "    Preprocess audio by loading, converting to mono, and computing a fixed-size Mel-spectrogram.\n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file.\n",
    "        target_sr (int): Target sampling rate.\n",
    "        n_fft (int): Number of FFT components.\n",
    "        hop_length (int): Hop length for STFT.\n",
    "        n_mels (int): Number of Mel bands.\n",
    "        fixed_length (int): Fixed time dimension for the spectrogram.\n",
    "    Returns:\n",
    "        mel_spectrogram_db (np.ndarray): Preprocessed Mel-spectrogram with fixed shape.\n",
    "    \"\"\"\n",
    "    signal, sr = librosa.load(audio_path, sr=target_sr, mono=True)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Ensure a fixed length along the time axis\n",
    "    if mel_spectrogram_db.shape[1] < fixed_length:\n",
    "        # Pad with zeros if shorter\n",
    "        mel_spectrogram_db = np.pad(mel_spectrogram_db, ((0, 0), (0, fixed_length - mel_spectrogram_db.shape[1])), mode='constant')\n",
    "    else:\n",
    "        # Truncate if longer\n",
    "        mel_spectrogram_db = mel_spectrogram_db[:, :fixed_length]\n",
    "    \n",
    "    return mel_spectrogram_db\n",
    "\n",
    "def load_dataset(data_path, fixed_length=128):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset into spectrograms and labels.\n",
    "    Args:\n",
    "        data_path (str): Path to the dataset.\n",
    "        fixed_length (int): Fixed time dimension for the spectrogram.\n",
    "    Returns:\n",
    "        dataset (np.ndarray): Array of preprocessed spectrograms.\n",
    "        labels (np.ndarray): Array of labels.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder)\n",
    "        # Skip non-directory files\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        label = 1 if folder == 'car_crash' else 0\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Check if the file is an audio file\n",
    "            if file_path.endswith('.wav'):\n",
    "                spectrogram = preprocess_audio(file_path, fixed_length=fixed_length)\n",
    "                dataset.append(spectrogram)\n",
    "                labels.append(label)\n",
    "    return np.array(dataset), np.array(labels)\n",
    "\n",
    "# Path to the dataset containing \"car_crash\" and other folders\n",
    "data_path = \"C:/Users/HP/Downloads/archive/Raw Audio/\"\n",
    "\n",
    "# Load dataset\n",
    "spectrograms, labels = load_dataset(data_path, fixed_length=128)\n",
    "\n",
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train / np.max(X_train)\n",
    "X_test = X_test / np.max(X_test)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa1c104-e565-4fb3-bc3c-ee7008c7c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 266ms/step - loss: 117357179568128.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 267ms/step - loss: 116613042929664.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 307ms/step - loss: 119993610010624.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 306ms/step - loss: 116747134828544.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 303ms/step - loss: 118839622762496.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - loss: 118381931921408.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 305ms/step - loss: 114749614325760.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 305ms/step - loss: 118171428192256.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 308ms/step - loss: 118123546017792.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 307ms/step - loss: 118994568740864.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 307ms/step - loss: 119258868613120.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 313ms/step - loss: 115307439980544.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 311ms/step - loss: 116531698597888.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - loss: 116657468997632.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 310ms/step - loss: 115791018065920.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 313ms/step - loss: 117797321441280.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 314ms/step - loss: 116246469148672.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - loss: 118226776227840.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 318ms/step - loss: 115937281835008.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 319ms/step - loss: 116120388370432.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 317ms/step - loss: 117677414678528.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 315ms/step - loss: 115355741585408.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 325ms/step - loss: 116273883119616.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 333ms/step - loss: 117305690292224.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 322ms/step - loss: 116774213255168.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 318ms/step - loss: 115801856147456.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 318ms/step - loss: 114289415290880.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 319ms/step - loss: 117222550798336.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 329ms/step - loss: 116654390378496.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 327ms/step - loss: 113833813213184.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 319ms/step - loss: 117146969440256.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 320ms/step - loss: 114791976796160.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 321ms/step - loss: 116762628587520.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 346ms/step - loss: 118414177730560.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 333ms/step - loss: 113830097059840.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 323ms/step - loss: 114208918208512.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 324ms/step - loss: 118020366139392.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 328ms/step - loss: 117227449745408.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 328ms/step - loss: 109858661597184.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 326ms/step - loss: 118656491061248.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 327ms/step - loss: 117965387202560.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 330ms/step - loss: 120874875224064.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 332ms/step - loss: 119036545335296.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 336ms/step - loss: 113633266761728.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 349ms/step - loss: 117378419523584.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 340ms/step - loss: 115921779687424.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 331ms/step - loss: 115231908954112.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 330ms/step - loss: 118272863240192.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 335ms/step - loss: 114447439888384.0000 - val_loss: 113018725728256.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 331ms/step - loss: 115827139411968.0000 - val_loss: 113018725728256.0000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 120806180913152.0000\n",
      "Test Loss: 118750309253120.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define DAE architecture\n",
    "def build_dae(input_shape):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return Model(input_img, decoded, name=\"DenoisingAutoencoder\")\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "X_train_dae = X_train / np.max(X_train)\n",
    "X_test_dae = X_test / np.max(X_test)\n",
    "\n",
    "# Reshape data for the DAE\n",
    "X_train_dae = X_train_dae[..., np.newaxis]\n",
    "X_test_dae = X_test_dae[..., np.newaxis]\n",
    "\n",
    "# Build and compile the DAE model\n",
    "dae = build_dae(X_train_dae[0].shape)\n",
    "dae.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')  # Use MSE for continuous data\n",
    "\n",
    "# Train the DAE\n",
    "history = dae.fit(\n",
    "    X_train_dae,\n",
    "    X_train_dae,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# Evaluate the DAE\n",
    "loss = dae.evaluate(X_test_dae, X_test_dae)\n",
    "print(f\"Test Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f279b46-c250-4b06-a33f-402340ea04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 535ms/step - accuracy: 0.9470 - loss: 0.4247 - val_accuracy: 0.9333 - val_loss: 0.2450\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 519ms/step - accuracy: 0.9353 - loss: 0.2401 - val_accuracy: 0.9333 - val_loss: 0.2537\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 519ms/step - accuracy: 0.9494 - loss: 0.2005 - val_accuracy: 0.9333 - val_loss: 0.2461\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 520ms/step - accuracy: 0.9395 - loss: 0.2310 - val_accuracy: 0.9333 - val_loss: 0.2470\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9419 - loss: 0.2234 - val_accuracy: 0.9333 - val_loss: 0.2466\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9430 - loss: 0.2239 - val_accuracy: 0.9333 - val_loss: 0.2489\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 520ms/step - accuracy: 0.9532 - loss: 0.1993 - val_accuracy: 0.9333 - val_loss: 0.2483\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9271 - loss: 0.2678 - val_accuracy: 0.9333 - val_loss: 0.2569\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 520ms/step - accuracy: 0.9325 - loss: 0.2568 - val_accuracy: 0.9333 - val_loss: 0.2459\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.9424 - loss: 0.2246 - val_accuracy: 0.9333 - val_loss: 0.2514\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9534 - loss: 0.1922 - val_accuracy: 0.9333 - val_loss: 0.2450\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9381 - loss: 0.2331 - val_accuracy: 0.9333 - val_loss: 0.2466\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 528ms/step - accuracy: 0.9437 - loss: 0.2190 - val_accuracy: 0.9333 - val_loss: 0.2456\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9502 - loss: 0.1994 - val_accuracy: 0.9333 - val_loss: 0.2453\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9338 - loss: 0.2454 - val_accuracy: 0.9333 - val_loss: 0.2523\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 522ms/step - accuracy: 0.9382 - loss: 0.2351 - val_accuracy: 0.9333 - val_loss: 0.2511\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9470 - loss: 0.2094 - val_accuracy: 0.9333 - val_loss: 0.2461\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.9483 - loss: 0.2052 - val_accuracy: 0.9333 - val_loss: 0.2504\n",
      "Epoch 19/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.9427 - loss: 0.2243 - val_accuracy: 0.9333 - val_loss: 0.2452\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.9437 - loss: 0.2178 - val_accuracy: 0.9333 - val_loss: 0.2457\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.9470 - loss: 0.2080 - val_accuracy: 0.9333 - val_loss: 0.2449\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.9527 - loss: 0.1938 - val_accuracy: 0.9333 - val_loss: 0.2464\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9419 - loss: 0.2244 - val_accuracy: 0.9333 - val_loss: 0.2482\n",
      "Epoch 24/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 528ms/step - accuracy: 0.9505 - loss: 0.1981 - val_accuracy: 0.9333 - val_loss: 0.2490\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9469 - loss: 0.2084 - val_accuracy: 0.9333 - val_loss: 0.2451\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9480 - loss: 0.2048 - val_accuracy: 0.9333 - val_loss: 0.2454\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 530ms/step - accuracy: 0.9554 - loss: 0.1852 - val_accuracy: 0.9333 - val_loss: 0.2455\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9466 - loss: 0.2094 - val_accuracy: 0.9333 - val_loss: 0.2457\n",
      "Epoch 29/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 528ms/step - accuracy: 0.9396 - loss: 0.2290 - val_accuracy: 0.9333 - val_loss: 0.2472\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 573ms/step - accuracy: 0.9497 - loss: 0.2005 - val_accuracy: 0.9333 - val_loss: 0.2454\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 548ms/step - accuracy: 0.9461 - loss: 0.2104 - val_accuracy: 0.9333 - val_loss: 0.2478\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 544ms/step - accuracy: 0.9484 - loss: 0.2033 - val_accuracy: 0.9333 - val_loss: 0.2459\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step - accuracy: 0.9404 - loss: 0.2263 - val_accuracy: 0.9333 - val_loss: 0.2508\n",
      "Epoch 34/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 538ms/step - accuracy: 0.9486 - loss: 0.2028 - val_accuracy: 0.9333 - val_loss: 0.2470\n",
      "Epoch 35/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 536ms/step - accuracy: 0.9500 - loss: 0.1992 - val_accuracy: 0.9333 - val_loss: 0.2456\n",
      "Epoch 36/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 538ms/step - accuracy: 0.9455 - loss: 0.2120 - val_accuracy: 0.9333 - val_loss: 0.2469\n",
      "Epoch 37/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 534ms/step - accuracy: 0.9451 - loss: 0.2133 - val_accuracy: 0.9333 - val_loss: 0.2474\n",
      "Epoch 38/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 562ms/step - accuracy: 0.9324 - loss: 0.2508 - val_accuracy: 0.9333 - val_loss: 0.2507\n",
      "Epoch 39/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.9483 - loss: 0.2060 - val_accuracy: 0.9333 - val_loss: 0.2451\n",
      "Epoch 40/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 533ms/step - accuracy: 0.9507 - loss: 0.2063 - val_accuracy: 0.9333 - val_loss: 0.2450\n",
      "Epoch 41/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 530ms/step - accuracy: 0.9488 - loss: 0.2051 - val_accuracy: 0.9333 - val_loss: 0.2457\n",
      "Epoch 42/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 533ms/step - accuracy: 0.9450 - loss: 0.2156 - val_accuracy: 0.9333 - val_loss: 0.2450\n",
      "Epoch 43/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 531ms/step - accuracy: 0.9469 - loss: 0.2116 - val_accuracy: 0.9333 - val_loss: 0.2450\n",
      "Epoch 44/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.9454 - loss: 0.2141 - val_accuracy: 0.9333 - val_loss: 0.2506\n",
      "Epoch 45/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.9450 - loss: 0.2143 - val_accuracy: 0.9333 - val_loss: 0.2510\n",
      "Epoch 46/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 531ms/step - accuracy: 0.9499 - loss: 0.1990 - val_accuracy: 0.9333 - val_loss: 0.2461\n",
      "Epoch 47/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 533ms/step - accuracy: 0.9404 - loss: 0.2267 - val_accuracy: 0.9333 - val_loss: 0.2497\n",
      "Epoch 48/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 530ms/step - accuracy: 0.9417 - loss: 0.2249 - val_accuracy: 0.9333 - val_loss: 0.2509\n",
      "Epoch 49/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 531ms/step - accuracy: 0.9364 - loss: 0.2421 - val_accuracy: 0.9333 - val_loss: 0.2473\n",
      "Epoch 50/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 534ms/step - accuracy: 0.9437 - loss: 0.2176 - val_accuracy: 0.9333 - val_loss: 0.2467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21387ff2dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GRU, Dense, Flatten, Input, Reshape, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define GCRNN architecture\n",
    "def build_gcrnn(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # TimeDistributed wrapper for Conv2D to process time steps separately\n",
    "    model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'), \n",
    "                               input_shape=input_shape))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(TimeDistributed(Flatten()))  # Flatten spatial dimensions while keeping time\n",
    "    model.add(GRU(64, activation='relu', return_sequences=True))  # GRU to capture temporal patterns\n",
    "    model.add(GRU(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
    "    return model\n",
    "\n",
    "# Use latent representations from the DAE as input\n",
    "latent_train = dae.predict(X_train_dae)  # Shape: (batch_size, height, width, 1)\n",
    "latent_test = dae.predict(X_test_dae)    # Shape: (batch_size, height, width, 1)\n",
    "\n",
    "# Add a \"time\" dimension to reshape the data for TimeDistributed layers\n",
    "latent_train = np.expand_dims(latent_train, axis=1)  # Shape: (batch_size, time_steps=1, height, width, channels=1)\n",
    "latent_test = np.expand_dims(latent_test, axis=1)    # Shape: (batch_size, time_steps=1, height, width, channels=1)\n",
    "\n",
    "# Build and compile the GCRNN\n",
    "gcrnn = build_gcrnn(latent_train.shape[1:])  # Shape: (time_steps, height, width, channels)\n",
    "gcrnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the GCRNN\n",
    "gcrnn.fit(latent_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de2e0e8c-fa59-490f-b7f8-732fb2dbcfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 519ms/step - accuracy: 0.9404 - loss: 1.0842 - val_accuracy: 0.9333 - val_loss: 0.6617\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 519ms/step - accuracy: 0.9469 - loss: 0.6814 - val_accuracy: 0.9333 - val_loss: 0.6764\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9517 - loss: 0.6519 - val_accuracy: 0.9333 - val_loss: 0.6671\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.7752 - loss: 0.7364 - val_accuracy: 0.9333 - val_loss: 0.6903\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 519ms/step - accuracy: 0.9436 - loss: 0.7006 - val_accuracy: 0.9333 - val_loss: 0.6843\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 520ms/step - accuracy: 0.9492 - loss: 0.6672 - val_accuracy: 0.9333 - val_loss: 0.6838\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9388 - loss: 0.7296 - val_accuracy: 0.9333 - val_loss: 0.6854\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9527 - loss: 0.6464 - val_accuracy: 0.9333 - val_loss: 0.6847\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 521ms/step - accuracy: 0.9423 - loss: 0.7086 - val_accuracy: 0.9333 - val_loss: 0.6837\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 520ms/step - accuracy: 0.9421 - loss: 0.7102 - val_accuracy: 0.9333 - val_loss: 0.6854\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 523ms/step - accuracy: 0.9484 - loss: 0.6723 - val_accuracy: 0.9333 - val_loss: 0.6864\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 522ms/step - accuracy: 0.9434 - loss: 0.7023 - val_accuracy: 0.9333 - val_loss: 0.6840\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 523ms/step - accuracy: 0.9521 - loss: 0.6498 - val_accuracy: 0.9333 - val_loss: 0.6807\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 523ms/step - accuracy: 0.9425 - loss: 0.7077 - val_accuracy: 0.9333 - val_loss: 0.6854\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9462 - loss: 0.6854 - val_accuracy: 0.9333 - val_loss: 0.6831\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.9509 - loss: 0.6569 - val_accuracy: 0.9333 - val_loss: 0.6843\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.9477 - loss: 0.6761 - val_accuracy: 0.9333 - val_loss: 0.6818\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.9390 - loss: 0.7285 - val_accuracy: 0.9333 - val_loss: 0.6852\n",
      "Epoch 19/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.9394 - loss: 0.7259 - val_accuracy: 0.9333 - val_loss: 0.6844\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 526ms/step - accuracy: 0.9404 - loss: 0.7199 - val_accuracy: 0.9333 - val_loss: 0.6835\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9403 - loss: 0.7209 - val_accuracy: 0.9333 - val_loss: 0.6837\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9569 - loss: 0.6206 - val_accuracy: 0.9333 - val_loss: 0.6779\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9492 - loss: 0.6668 - val_accuracy: 0.9333 - val_loss: 0.6835\n",
      "Epoch 24/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9508 - loss: 0.6574 - val_accuracy: 0.9333 - val_loss: 0.6829\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9605 - loss: 0.5991 - val_accuracy: 0.9333 - val_loss: 0.6794\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 528ms/step - accuracy: 0.9519 - loss: 0.6509 - val_accuracy: 0.9333 - val_loss: 0.6825\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 526ms/step - accuracy: 0.9306 - loss: 0.7797 - val_accuracy: 0.9333 - val_loss: 0.6839\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9417 - loss: 0.7125 - val_accuracy: 0.9333 - val_loss: 0.6820\n",
      "Epoch 29/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9474 - loss: 0.6778 - val_accuracy: 0.9333 - val_loss: 0.6833\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 535ms/step - accuracy: 0.9505 - loss: 0.6595 - val_accuracy: 0.9333 - val_loss: 0.6794\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.9510 - loss: 0.6562 - val_accuracy: 0.9333 - val_loss: 0.6820\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 540ms/step - accuracy: 0.9534 - loss: 0.6418 - val_accuracy: 0.9333 - val_loss: 0.6802\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 559ms/step - accuracy: 0.9412 - loss: 0.7153 - val_accuracy: 0.9333 - val_loss: 0.6815\n",
      "Epoch 34/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 537ms/step - accuracy: 0.9389 - loss: 0.7293 - val_accuracy: 0.9333 - val_loss: 0.6849\n",
      "Epoch 35/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 536ms/step - accuracy: 0.9376 - loss: 0.7370 - val_accuracy: 0.9333 - val_loss: 0.6810\n",
      "Epoch 36/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 534ms/step - accuracy: 0.9468 - loss: 0.6815 - val_accuracy: 0.9333 - val_loss: 0.6836\n",
      "Epoch 37/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9488 - loss: 0.6697 - val_accuracy: 0.9333 - val_loss: 0.6822\n",
      "Epoch 38/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 530ms/step - accuracy: 0.9464 - loss: 0.6841 - val_accuracy: 0.9333 - val_loss: 0.6834\n",
      "Epoch 39/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9486 - loss: 0.6710 - val_accuracy: 0.9333 - val_loss: 0.6832\n",
      "Epoch 40/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9431 - loss: 0.7038 - val_accuracy: 0.9333 - val_loss: 0.6829\n",
      "Epoch 41/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 530ms/step - accuracy: 0.9462 - loss: 0.6853 - val_accuracy: 0.9333 - val_loss: 0.6833\n",
      "Epoch 42/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9434 - loss: 0.7022 - val_accuracy: 0.9333 - val_loss: 0.6832\n",
      "Epoch 43/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 532ms/step - accuracy: 0.9493 - loss: 0.6669 - val_accuracy: 0.9333 - val_loss: 0.6826\n",
      "Epoch 44/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9493 - loss: 0.6663 - val_accuracy: 0.9333 - val_loss: 0.6797\n",
      "Epoch 45/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 564ms/step - accuracy: 0.9424 - loss: 0.7083 - val_accuracy: 0.9333 - val_loss: 0.6813\n",
      "Epoch 46/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9533 - loss: 0.6421 - val_accuracy: 0.9333 - val_loss: 0.6825\n",
      "Epoch 47/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.9410 - loss: 0.7165 - val_accuracy: 0.9333 - val_loss: 0.6824\n",
      "Epoch 48/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 526ms/step - accuracy: 0.9429 - loss: 0.7051 - val_accuracy: 0.9333 - val_loss: 0.6838\n",
      "Epoch 49/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 527ms/step - accuracy: 0.9350 - loss: 0.7524 - val_accuracy: 0.9333 - val_loss: 0.6826\n",
      "Epoch 50/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 529ms/step - accuracy: 0.9565 - loss: 0.6232 - val_accuracy: 0.9333 - val_loss: 0.6796\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00       318\n",
      "    Positive       0.05      1.00      0.10        18\n",
      "\n",
      "    accuracy                           0.05       336\n",
      "   macro avg       0.03      0.50      0.05       336\n",
      "weighted avg       0.00      0.05      0.01       336\n",
      "\n",
      "AUC-ROC: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model\n",
    "gcrnn.fit(latent_train, y_train, epochs=50, batch_size=32, validation_split=0.1, class_weight=class_weights)\n",
    "\n",
    "# Make predictions with a custom threshold\n",
    "threshold = 0.3\n",
    "y_pred_proba = gcrnn.predict(latent_test)\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC-ROC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762b924-18ab-4d79-ba78-e5eda2ebf02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
